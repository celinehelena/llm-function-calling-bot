# Projeto: Integra√ß√£o de LLM com API via Function Calling

Este reposit√≥rio re√∫ne dois componentes principais que demonstram a integra√ß√£o de **Modelos de Linguagem Grandes (LLMs)** com sistemas externos por meio da funcionalidade **Function Calling**, utilizando o modelo **Gemini da Google**, a biblioteca **LangChain**, e uma **API acad√™mica simulada** desenvolvida com FastAPI.

## Estrutura do Reposit√≥rio
üìÅ api_fast ‚Üí API simulando um sistema acad√™mico (marca√ß√£o de presen√ßa e listagem de registro).

üìÅ gemini-bot-project ‚Üí Bot gen√©rico em Python com suporte a LLM e Function Calling.


## üí° Objetivo

Explorar como os LLMs podem interagir com APIs externas por meio da funcionalidade de **chamadas de fun√ß√£o (Function Calling)**, interpretando comandos em linguagem natural e executando a√ß√µes de forma automatizada com suporte do **LangChain**.

## üöÄ Como Rodar o Projeto

### 1. Clonando o reposit√≥rio
```bash
git clone https://github.com/seu-usuario/nome-do-repositorio.git
cd nome-do-repositorio
```

### 2. Executando a API (FastAPI)
#### Pr√©-requisitos:
- Python 3.10+
- FastAPI
- Uvicorn
#### Passos:
```bash
cd api_fast
pip install -r requirements.txt
uvicorn main:app --reload
```

### 3. Executando o Bot com LLM
#### Pr√©-requisitos:
- Python 3.10+
- LangChain
- Google Generative AI SDK (Gemini)
- python-dotenv
  
#### Passos:
```bash
cd ../gemini-bot-project
pip install -r requirements.txt
```
Crie um arquivo .env com as seguintes vari√°veis:
```bash
GOOGLE_API_KEY=your_gemini_api_key
API_URL=http://localhost:8000
```

Ent√£o, execute:

```bash
python main.py
```

O bot estar√° pronto para receber comandos e interagir com a API.
